{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install motmetrics\n",
        "!pip install deep-sort-realtime\n",
        "!git clone https://github.com/abewley/sort.git\n",
        "!pip install filterpy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZZBIC9IBmOr",
        "outputId": "260f1ea1-341f-4dcc-d4c2-80ff9c942dcc"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: motmetrics in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (2.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (1.13.1)\n",
            "Requirement already satisfied: xmltodict>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (0.14.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.1->motmetrics) (1.17.0)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (4.11.0.86)\n",
            "fatal: destination path 'sort' already exists and is not an empty directory.\n",
            "Requirement already satisfied: filterpy in /usr/local/lib/python3.11/dist-packages (1.4.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from filterpy) (1.13.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from filterpy) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->filterpy) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->filterpy) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Imports</h3>"
      ],
      "metadata": {
        "id": "oS2WQBbNOqPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')  # non-interactive backend suitable for headless environments\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import motmetrics as mm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "import sys\n",
        "\n",
        "# Fix sort.py backend issue\n",
        "with open('/content/sort/sort.py', 'r') as file:\n",
        "    code = file.read()\n",
        "\n",
        "# Replace TkAgg with Agg\n",
        "fixed_code = code.replace('TkAgg', 'Agg')\n",
        "\n",
        "with open('/content/sort/sort.py', 'w') as file:\n",
        "    file.write(fixed_code)\n",
        "\n",
        "print(\"Backend issue fixed!\")\n",
        "\n",
        "sys.path.append('/content/sort')\n"
      ],
      "metadata": {
        "id": "DdDK0YteBk8d",
        "outputId": "36c9d83b-bb3f-47b4-e130-07f006830c44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Backend issue fixed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Configuration & Device Setup</h3>"
      ],
      "metadata": {
        "id": "hyHibUZxObhK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CONFIGURATION\n",
        "CONFIG = {\n",
        "    \"dataset_url\": \"https://drive.google.com/uc?id=1yvOwbPks7dFzMX2z4JoUQlwdEfNYQd7-\",\n",
        "    \"dataset_zip\": \"/content/MOT15.zip\",\n",
        "    \"dataset_path\": \"/content/MOT15\",\n",
        "    \"tracking\": {\"iou_threshold\": 0.3, \"max_age\": 30},\n",
        "    \"training\": {\"epochs\": 5, \"batch_size\": 8, \"learning_rate\": 0.0001},\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ],
      "metadata": {
        "id": "wHcmNWlaOaul",
        "outputId": "2b9e04a9-f4f0-4034-b0e6-4b4439a7403d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Dataset Download & Extraction Functions</h3>"
      ],
      "metadata": {
        "id": "z5tnOYP6OeFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DOWNLOAD & EXTRACT DATASET\n",
        "def download_dataset():\n",
        "    if not os.path.exists(CONFIG[\"dataset_zip\"]):\n",
        "        print(\"Downloading MOT15 dataset from Google Drive...\")\n",
        "        gdown.download(CONFIG[\"dataset_url\"], CONFIG[\"dataset_zip\"], quiet=False)\n",
        "    else:\n",
        "        print(\"Dataset already downloaded.\")\n",
        "\n",
        "def extract_dataset():\n",
        "    if not os.path.exists(CONFIG[\"dataset_path\"]):\n",
        "        print(\"Extracting dataset...\")\n",
        "        with zipfile.ZipFile(CONFIG[\"dataset_zip\"], 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"/content/\")\n",
        "        print(f\"Dataset extracted to {CONFIG['dataset_path']}\")\n",
        "    else:\n",
        "        print(\"Dataset already extracted.\")\n"
      ],
      "metadata": {
        "id": "M7_zZPQ_Od9b"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Data Augmentation Function</h3>"
      ],
      "metadata": {
        "id": "dQnWc1v1PXZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA AUGMENTATION\n",
        "def apply_augmentations(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((640, 640)),\n",
        "        transforms.RandomCrop(600),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transform(image)\n"
      ],
      "metadata": {
        "id": "junlfzkIOd6V"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>MOT15Dataset Class</h3>"
      ],
      "metadata": {
        "id": "KMgKPdwxPU2D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# MOT15 DATASET CLASS\n",
        "class MOT15Dataset(Dataset):\n",
        "    def __init__(self, root_dir, mode=\"train\", transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, mode)\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        for seq in os.listdir(self.root_dir):\n",
        "            img_dir = os.path.join(self.root_dir, seq, \"img1\")\n",
        "            gt_path = os.path.join(self.root_dir, seq, \"gt/gt.txt\")\n",
        "            if os.path.exists(gt_path):\n",
        "                gt_df = pd.read_csv(gt_path, header=None)\n",
        "                gt_df.columns = [\"frame\", \"track_id\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"class\", \"visibility\", \"unused\"]\n",
        "                for img_name in sorted(os.listdir(img_dir)):\n",
        "                    frame_id = int(img_name.split('.')[0])\n",
        "                    frame_gt = gt_df[gt_df[\"frame\"] == frame_id]\n",
        "                    boxes_df = frame_gt[[\"x\", \"y\", \"w\", \"h\"]].copy()\n",
        "                    boxes_df = pd.DataFrame({\n",
        "                        'x1': boxes_df['x'],\n",
        "                        'y1': boxes_df['y'],\n",
        "                        'x2': boxes_df['x'] + boxes_df['w'],\n",
        "                        'y2': boxes_df['y'] + boxes_df['h']\n",
        "                    })\n",
        "                    boxes = boxes_df[['x1', 'y1', 'x2', 'y2']].values\n",
        "                    labels = np.ones(len(boxes))\n",
        "                    self.data.append((os.path.join(img_dir, img_name), boxes, labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, boxes, labels = self.data[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        target = {\"boxes\": torch.tensor(boxes, dtype=torch.float32), \"labels\": torch.tensor(labels, dtype=torch.int64)}\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n"
      ],
      "metadata": {
        "id": "qtlucLyOOd3T"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Object Detector Class</h3>"
      ],
      "metadata": {
        "id": "FHpozzwxPg7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# OBJECT DETECTOR CLASS\n",
        "class ObjectDetector:\n",
        "    def __init__(self, num_classes=2):\n",
        "        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "        self.model.to(device)\n",
        "        self.model.train()\n",
        "\n",
        "    def detect_objects(self, images):\n",
        "        img_tensors = [apply_augmentations(img).to(device) for img in images]\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(img_tensors)\n",
        "        return predictions\n"
      ],
      "metadata": {
        "id": "F_fcnxF6Od0R"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Adaptive Tracker Class</h3>"
      ],
      "metadata": {
        "id": "GOTKtPDdPp-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ADAPTIVE TRACKER CLASS\n",
        "# Make sure that Sort is imported from your fixed sort.py file.\n",
        "from sort import Sort\n",
        "\n",
        "class AdaptiveTracker:\n",
        "    def __init__(self):\n",
        "        self.deep_sort = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.2)\n",
        "        self.sort_tracker = Sort()\n",
        "        self.previous_tracks = {}\n",
        "\n",
        "    def track_objects(self, detections, frame_num):\n",
        "        sort_tracked = self.sort_tracker.update(np.array(detections) if detections else np.empty((0, 5)))\n",
        "        deep_sort_tracked = self.deep_sort.update_tracks(detections, frame_num=frame_num)\n",
        "\n",
        "        consistent_tracks = []\n",
        "        for track in deep_sort_tracked:\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_tlbr()\n",
        "            if track_id in self.previous_tracks:\n",
        "                prev_bbox = self.previous_tracks[track_id]\n",
        "                if np.linalg.norm(np.array(bbox[:2]) - np.array(prev_bbox[:2])) < 50:\n",
        "                    consistent_tracks.append(track)\n",
        "            else:\n",
        "                consistent_tracks.append(track)\n",
        "            self.previous_tracks[track_id] = bbox\n",
        "\n",
        "        return sort_tracked, consistent_tracks\n"
      ],
      "metadata": {
        "id": "BqCtDofvOdxR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Training & Evaluation Functions</h3>"
      ],
      "metadata": {
        "id": "JwkTT-oNPt_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING FUNCTION\n",
        "def train_faster_rcnn(model, train_loader, epochs=10, lr=0.0001):\n",
        "    optimizer = torch.optim.Adam(model.model.parameters(), lr=lr)\n",
        "    model.model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{\"boxes\": t[\"boxes\"].to(device), \"labels\": t[\"labels\"].to(device)} for t in targets]\n",
        "            optimizer.zero_grad()\n",
        "            loss_dict = model.model(images, targets)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# PERFORMANCE EVALUATION FUNCTION\n",
        "def evaluate_performance(detections, dataset):\n",
        "    acc = mm.MOTAccumulator(auto_id=True)\n",
        "    for idx, det in enumerate(detections):\n",
        "        print(f\"Frame {idx}: Detected track IDs: {det['track_id']}, Bounding boxes: {det['bboxes']}\")\n",
        "        gt_boxes = dataset[idx][1][\"boxes\"].numpy()\n",
        "        gt_ids = np.arange(len(gt_boxes))\n",
        "        det_boxes = np.array(det[\"bboxes\"])\n",
        "        det_ids = det[\"track_id\"]\n",
        "        distances = mm.distances.iou_matrix(gt_boxes, det_boxes, max_iou=0.3)\n",
        "        acc.update(gt_ids, det_ids, distances)\n",
        "\n",
        "    mh = mm.metrics.create()\n",
        "    summary = mh.compute(acc, metrics=['mota', 'motp', 'idf1', 'num_switches'], name='Overall')\n",
        "    print(summary)\n",
        "\n",
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n"
      ],
      "metadata": {
        "id": "JRvHBCPjOduV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Main Execution</h3>"
      ],
      "metadata": {
        "id": "t2xXWubbPyKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "B8jVoGXPat5X",
        "outputId": "9369afdb-cdbe-40f5-8def-cdddc59d3c74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Mar  9 07:02:31 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   56C    P0             30W /   70W |   10464MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Download and extract dataset\n",
        "    download_dataset()\n",
        "    extract_dataset()\n",
        "\n",
        "    # Create dataset and dataloaders\n",
        "    train_dataset = MOT15Dataset(CONFIG[\"dataset_path\"], mode=\"train\", transform=apply_augmentations)\n",
        "    test_dataset = MOT15Dataset(CONFIG[\"dataset_path\"], mode=\"test\", transform=apply_augmentations)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"training\"][\"batch_size\"], shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"training\"][\"batch_size\"], shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Initialize detector and tracker\n",
        "    detector = ObjectDetector(num_classes=2)\n",
        "    train_faster_rcnn(detector, train_loader, epochs=CONFIG[\"training\"][\"epochs\"], lr=CONFIG[\"training\"][\"learning_rate\"])\n",
        "\n",
        "    tracker = AdaptiveTracker()\n",
        "    all_detections = []\n",
        "    for frame_num, (images, _) in tqdm(enumerate(test_loader), desc=\"Evaluating\"):\n",
        "        detections = detector.detect_objects(images)\n",
        "        _, consistent_tracks = tracker.track_objects(detections, frame_num)\n",
        "        all_detections.append({\n",
        "            \"track_id\": [t.track_id for t in consistent_tracks],\n",
        "            \"bboxes\": [t.to_tlbr() for t in consistent_tracks]\n",
        "        })\n",
        "\n",
        "    evaluate_performance(all_detections, test_dataset)\n",
        "    print(\"Training & Tracking Completed!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0WixXs3cOdrX",
        "outputId": "8d9b6db3-f2f7-49b7-ce7f-3d1298cedb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already downloaded.\n",
            "Dataset already extracted.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 688/688 [26:15<00:00,  2.29s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 4340.0728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/5: 100%|██████████| 688/688 [25:35<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2, Loss: 2974.5502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/5: 100%|██████████| 688/688 [25:18<00:00,  2.21s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3, Loss: 2696.1500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/5:  30%|██▉       | 203/688 [07:30<17:46,  2.20s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "b6NlE39SOcvi"
      }
    }
  ]
}