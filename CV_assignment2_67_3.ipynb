{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install motmetrics\n",
        "!pip install deep-sort-realtime\n",
        "!git clone https://github.com/abewley/sort.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZZBIC9IBmOr",
        "outputId": "c072dfef-c905-4d50-8fa1-f604c8d37e59"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: motmetrics in /usr/local/lib/python3.11/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (1.26.4)\n",
            "Requirement already satisfied: pandas>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (2.2.2)\n",
            "Requirement already satisfied: scipy>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (1.13.1)\n",
            "Requirement already satisfied: xmltodict>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from motmetrics) (0.14.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.1->motmetrics) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.23.1->motmetrics) (1.17.0)\n",
            "Requirement already satisfied: deep-sort-realtime in /usr/local/lib/python3.11/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (from deep-sort-realtime) (4.11.0.86)\n",
            "fatal: destination path 'sort' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "JYYrFMRMsz6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "2e01e4e6-f6e5-4553-8af4-b36e281b8fe2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Backend issue fixed!\n",
            "✅ Dataset already downloaded.\n",
            "✅ Dataset already extracted.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Length mismatch: Expected axis has 10 elements, new values have 9 elements",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-bb38056fbd5c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0mextract_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m     \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOT15Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_augmentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMOT15Dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dataset_path\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapply_augmentations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0mtrain_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mCONFIG\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"training\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"batch_size\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-bb38056fbd5c>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root_dir, mode, transform)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0mgt_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m                 \u001b[0mgt_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"track_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"y\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"h\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"conf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"class\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"visibility\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mimg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m                     \u001b[0mframe_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   6311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6312\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6315\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mproperties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \"\"\"\n\u001b[1;32m    813\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAxisInt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;31m# Caller is responsible for ensuring we have an Index object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/internals/base.py\u001b[0m in \u001b[0;36m_validate_set_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34mf\"values have {new_len} elements\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 10 elements, new values have 9 elements"
          ]
        }
      ],
      "source": [
        "import matplotlib\n",
        "matplotlib.use('Agg')  # non-interactive backend suitable for headless environments\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import gdown\n",
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import motmetrics as mm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import transforms\n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "from tqdm import tqdm\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "# Fix sort.py backend issue\n",
        "with open('/content/sort/sort.py', 'r') as file:\n",
        "    code = file.read()\n",
        "\n",
        "# Replace TkAgg with Agg\n",
        "fixed_code = code.replace('TkAgg', 'Agg')\n",
        "\n",
        "with open('/content/sort/sort.py', 'w') as file:\n",
        "    file.write(fixed_code)\n",
        "\n",
        "print(\"✅ Backend issue fixed!\")\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/sort')\n",
        "\n",
        "\n",
        "\n",
        "# ✅ CONFIGURATION\n",
        "CONFIG = {\n",
        "    \"dataset_url\": \"https://drive.google.com/uc?id=1yvOwbPks7dFzMX2z4JoUQlwdEfNYQd7-\",\n",
        "    \"dataset_zip\": \"/content/MOT15.zip\",\n",
        "    \"dataset_path\": \"/content/MOT15\",\n",
        "    \"tracking\": {\"iou_threshold\": 0.3, \"max_age\": 30},\n",
        "    \"training\": {\"epochs\": 10, \"batch_size\": 8, \"learning_rate\": 0.0001},\n",
        "}\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ✅ DOWNLOAD & EXTRACT DATASET\n",
        "def download_dataset():\n",
        "    if not os.path.exists(CONFIG[\"dataset_zip\"]):\n",
        "        print(\"📥 Downloading MOT15 dataset from Google Drive...\")\n",
        "        gdown.download(CONFIG[\"dataset_url\"], CONFIG[\"dataset_zip\"], quiet=False)\n",
        "    else:\n",
        "        print(\"✅ Dataset already downloaded.\")\n",
        "\n",
        "def extract_dataset():\n",
        "    if not os.path.exists(CONFIG[\"dataset_path\"]):\n",
        "        print(\"📂 Extracting dataset...\")\n",
        "        with zipfile.ZipFile(CONFIG[\"dataset_zip\"], 'r') as zip_ref:\n",
        "            zip_ref.extractall(\"/content/\")\n",
        "        print(f\"✅ Dataset extracted to {CONFIG['dataset_path']}\")\n",
        "    else:\n",
        "        print(\"✅ Dataset already extracted.\")\n",
        "\n",
        "# ✅ DATA AUGMENTATION\n",
        "def apply_augmentations(image):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((640, 640)),\n",
        "        transforms.RandomCrop(600),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "        transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    return transform(image)\n",
        "\n",
        "# ✅ MOT15 DATASET CLASS\n",
        "class MOT15Dataset(Dataset):\n",
        "    def __init__(self, root_dir, mode=\"train\", transform=None):\n",
        "        self.root_dir = os.path.join(root_dir, mode)\n",
        "        self.transform = transform\n",
        "        self.data = []\n",
        "        for seq in os.listdir(self.root_dir):\n",
        "            img_dir = os.path.join(self.root_dir, seq, \"img1\")\n",
        "            gt_path = os.path.join(self.root_dir, seq, \"gt/gt.txt\")\n",
        "            if os.path.exists(gt_path):\n",
        "                gt_df = pd.read_csv(gt_path, header=None)\n",
        "                gt_df.columns = [\"frame\", \"track_id\", \"x\", \"y\", \"w\", \"h\", \"conf\", \"class\", \"visibility\"]\n",
        "                for img_name in sorted(os.listdir(img_dir)):\n",
        "                    frame_id = int(img_name.split('.')[0])\n",
        "                    frame_gt = gt_df[gt_df[\"frame\"] == frame_id]\n",
        "                    boxes_df = frame_gt[[\"x\", \"y\", \"w\", \"h\"]].copy()\n",
        "                    boxes_df = pd.DataFrame({\n",
        "                    'x1': boxes_df['x'],\n",
        "                    'y1': boxes_df['y'],\n",
        "                    'x2': boxes_df['x'] + boxes_df['w'],\n",
        "                    'y2': boxes_df['y'] + boxes_df['h']\n",
        "                    })\n",
        "                    boxes = boxes_df[['x1', 'y1', 'x2', 'y2']].values\n",
        "                    labels = np.ones(len(boxes))\n",
        "                    self.data.append((os.path.join(img_dir, img_name), boxes, labels))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path, boxes, labels = self.data[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        target = {\"boxes\": torch.tensor(boxes, dtype=torch.float32), \"labels\": torch.tensor(labels, dtype=torch.int64)}\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, target\n",
        "\n",
        "# ✅ OBJECT DETECTOR CLASS\n",
        "class ObjectDetector:\n",
        "    def __init__(self, num_classes=2):\n",
        "        self.model = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights=\"DEFAULT\")\n",
        "        in_features = self.model.roi_heads.box_predictor.cls_score.in_features\n",
        "        self.model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
        "        self.model.to(device)\n",
        "        self.model.train()\n",
        "\n",
        "    def detect_objects(self, images):\n",
        "        img_tensors = [apply_augmentations(img).to(device) for img in images]\n",
        "        with torch.no_grad():\n",
        "            predictions = self.model(img_tensors)\n",
        "        return predictions\n",
        "\n",
        "# ✅ ADAPTIVE TRACKER CLASS\n",
        "class AdaptiveTracker:\n",
        "    def __init__(self):\n",
        "        self.deep_sort = DeepSort(max_age=30, n_init=3, max_cosine_distance=0.2)\n",
        "        self.sort_tracker = Sort()\n",
        "        self.previous_tracks = {}\n",
        "\n",
        "    def track_objects(self, detections, frame_num):\n",
        "        sort_tracked = self.sort_tracker.update(np.array(detections) if detections else np.empty((0, 5)))\n",
        "        deep_sort_tracked = self.deep_sort.update_tracks(detections, frame_num=frame_num)\n",
        "\n",
        "        consistent_tracks = []\n",
        "        for track in deep_sort_tracked:\n",
        "            track_id = track.track_id\n",
        "            bbox = track.to_tlbr()\n",
        "            if track_id in self.previous_tracks:\n",
        "                prev_bbox = self.previous_tracks[track_id]\n",
        "                if np.linalg.norm(np.array(bbox[:2]) - np.array(prev_bbox[:2])) < 50:\n",
        "                    consistent_tracks.append(track)\n",
        "            else:\n",
        "                consistent_tracks.append(track)\n",
        "            self.previous_tracks[track_id] = bbox\n",
        "\n",
        "        return sort_tracked, consistent_tracks\n",
        "\n",
        "# ✅ TRAINING FUNCTION\n",
        "def train_faster_rcnn(model, train_loader, epochs=10, lr=0.0001):\n",
        "    optimizer = torch.optim.Adam(model.model.parameters(), lr=lr)\n",
        "    model.model.train()\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss = 0\n",
        "        for images, targets in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\"):\n",
        "            images = [img.to(device) for img in images]\n",
        "            targets = [{\"boxes\": t[\"boxes\"].to(device), \"labels\": t[\"labels\"].to(device)} for t in targets]\n",
        "            optimizer.zero_grad()\n",
        "            loss_dict = model.model(images, targets)\n",
        "            loss = sum(loss for loss in loss_dict.values())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            epoch_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")\n",
        "\n",
        "# ✅ PERFORMANCE EVALUATION FUNCTION\n",
        "def evaluate_performance(detections, dataset):\n",
        "    acc = mm.MOTAccumulator(auto_id=True)\n",
        "    for idx, det in enumerate(detections):\n",
        "        gt_boxes = dataset[idx][1][\"boxes\"].numpy()\n",
        "        gt_ids = np.arange(len(gt_boxes))\n",
        "        det_boxes = np.array(det[\"bboxes\"])\n",
        "        det_ids = det[\"track_id\"]\n",
        "        distances = mm.distances.iou_matrix(gt_boxes, det_boxes, max_iou=0.5)\n",
        "        acc.update(gt_ids, det_ids, distances)\n",
        "\n",
        "    mh = mm.metrics.create()\n",
        "    summary = mh.compute(acc, metrics=['mota', 'motp', 'idf1', 'num_switches'], name='Overall')\n",
        "    print(summary)\n",
        "\n",
        "# ✅ MAIN EXECUTION\n",
        "if __name__ == \"__main__\":\n",
        "    download_dataset()\n",
        "    extract_dataset()\n",
        "\n",
        "    train_dataset = MOT15Dataset(CONFIG[\"dataset_path\"], mode=\"train\", transform=apply_augmentations)\n",
        "    test_dataset = MOT15Dataset(CONFIG[\"dataset_path\"], mode=\"test\", transform=apply_augmentations)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=CONFIG[\"training\"][\"batch_size\"], shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=CONFIG[\"training\"][\"batch_size\"], shuffle=False)\n",
        "\n",
        "    detector = ObjectDetector(num_classes=2)\n",
        "    train_faster_rcnn(detector, train_loader, epochs=CONFIG[\"training\"][\"epochs\"], lr=CONFIG[\"training\"][\"learning_rate\"])\n",
        "\n",
        "    tracker = AdaptiveTracker()\n",
        "    all_detections = []\n",
        "    for frame_num, (images, _) in tqdm(enumerate(test_loader), desc=\"Evaluating\"):\n",
        "        detections = detector.detect_objects(images)\n",
        "        _, consistent_tracks = tracker.track_objects(detections, frame_num)\n",
        "        all_detections.append({\"track_id\": [t.track_id for t in consistent_tracks],\n",
        "                               \"bboxes\": [t.to_tlbr() for t in consistent_tracks]})\n",
        "\n",
        "    evaluate_performance(all_detections, test_dataset)\n",
        "    print(\"✅ Training & Tracking Completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DdDK0YteBk8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}